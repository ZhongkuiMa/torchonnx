"""PyTorch module generated by TorchONNX.

Source: /mnt/hdd1/zhongkui/rover_project/rover_alpha/torchonnx/tests/vnncomp2024_benchmarks/nn4sys_2023/onnx/mscn_2048d.onnx
Generated: 2025-12-22 03:36:19

This module was automatically converted from an ONNX model.
"""

__all__ = ["Nn4sys2023Mscn2048d"]

import torch
import torch.nn as nn


class Nn4sys2023Mscn2048d(nn.Module):
    def __init__(self):
        super().__init__()
        self.register_buffer("c27", torch.empty([6, 2048], dtype=torch.float32))
        self.register_buffer("c28", torch.empty([2048], dtype=torch.float32))
        self.register_buffer("c29", torch.empty([2048, 2048], dtype=torch.float32))
        self.register_buffer("c30", torch.empty([2048], dtype=torch.float32))
        self.register_buffer("c31", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c32", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c33", torch.empty([13, 2048], dtype=torch.float32))
        self.register_buffer("c34", torch.empty([2048], dtype=torch.float32))
        self.register_buffer("c35", torch.empty([2048, 2048], dtype=torch.float32))
        self.register_buffer("c36", torch.empty([2048], dtype=torch.float32))
        self.register_buffer("c37", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c38", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c39", torch.empty([6, 2048], dtype=torch.float32))
        self.register_buffer("c40", torch.empty([2048], dtype=torch.float32))
        self.register_buffer("c41", torch.empty([2048, 2048], dtype=torch.float32))
        self.register_buffer("c42", torch.empty([2048], dtype=torch.float32))
        self.register_buffer("c43", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c44", torch.empty([1], dtype=torch.int64))
        self.relu1 = nn.ReLU()
        self.relu2 = nn.ReLU()
        self.relu3 = nn.ReLU()
        self.relu4 = nn.ReLU()
        self.relu5 = nn.ReLU()
        self.relu6 = nn.ReLU()
        self.linear1 = nn.Linear(6144, 2048)
        self.relu7 = nn.ReLU()
        self.linear2 = nn.Linear(2048, 1)
        self.sigmoid1 = nn.Sigmoid()

    def forward(self, x0):
        x1 = x0[:, 0:3]
        x2 = x1[:, :, 0:7]
        x3, x4 = x2.split([6, 1], dim=-1)
        x5 = x0[:, 3:9]
        x6 = x5[:, :, 0:14]
        x7, x8 = x6.split([13, 1], dim=-1)
        x9 = x0[:, 9:11]
        x10 = x9[:, :, 0:7]
        x11, x12 = x10.split([6, 1], dim=-1)
        x13 = x3 @ self.c27
        x14 = self.c28 + x13
        x15 = self.relu1(x14)
        x16 = x15 @ self.c29
        x17 = self.c30 + x16
        x18 = self.relu2(x17)
        x19 = x18 * x4
        x20 = torch.sum(x19, self.c31.tolist(), keepdim=False)
        x21 = torch.sum(x4, self.c32.tolist(), keepdim=False)
        x22 = x20 / x21
        x23 = x7 @ self.c33
        x24 = self.c34 + x23
        x25 = self.relu3(x24)
        x26 = x25 @ self.c35
        x27 = self.c36 + x26
        x28 = self.relu4(x27)
        x29 = x28 * x8
        x30 = torch.sum(x29, self.c37.tolist(), keepdim=False)
        x31 = torch.sum(x8, self.c38.tolist(), keepdim=False)
        x32 = x30 / x31
        x33 = x11 @ self.c39
        x34 = self.c40 + x33
        x35 = self.relu5(x34)
        x36 = x35 @ self.c41
        x37 = self.c42 + x36
        x38 = self.relu6(x37)
        x39 = x38 * x12
        x40 = torch.sum(x39, self.c43.tolist(), keepdim=False)
        x41 = torch.sum(x12, self.c44.tolist(), keepdim=False)
        x42 = x40 / x41
        x43 = torch.cat([x22, x32, x42], dim=1)
        x44 = self.linear1(x43)
        x45 = self.relu7(x44)
        x46 = self.linear2(x45)
        x47 = self.sigmoid1(x46)
        return x47
