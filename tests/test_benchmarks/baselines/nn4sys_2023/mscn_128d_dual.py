"""PyTorch module generated by TorchONNX.

Source: /mnt/hdd1/zhongkui/rover_project/rover_alpha/torchonnx/tests/vnncomp2024_benchmarks/nn4sys_2023/onnx/mscn_128d_dual.onnx
Generated: 2025-12-22 03:36:18

This module was automatically converted from an ONNX model.
"""

__all__ = ["Nn4sys2023Mscn128dDual"]

import torch
import torch.nn as nn


class Nn4sys2023Mscn128dDual(nn.Module):
    def __init__(self):
        super().__init__()
        self.register_buffer("c35", torch.empty([6, 128], dtype=torch.float32))
        self.register_buffer("c36", torch.empty([128], dtype=torch.float32))
        self.register_buffer("c37", torch.empty([128, 128], dtype=torch.float32))
        self.register_buffer("c38", torch.empty([128], dtype=torch.float32))
        self.register_buffer("c39", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c40", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c41", torch.empty([13, 128], dtype=torch.float32))
        self.register_buffer("c42", torch.empty([128], dtype=torch.float32))
        self.register_buffer("c43", torch.empty([128, 128], dtype=torch.float32))
        self.register_buffer("c44", torch.empty([128], dtype=torch.float32))
        self.register_buffer("c45", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c46", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c47", torch.empty([6, 128], dtype=torch.float32))
        self.register_buffer("c48", torch.empty([128], dtype=torch.float32))
        self.register_buffer("c49", torch.empty([128, 128], dtype=torch.float32))
        self.register_buffer("c50", torch.empty([128], dtype=torch.float32))
        self.register_buffer("c51", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c52", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c80", torch.empty([6, 128], dtype=torch.float32))
        self.register_buffer("c81", torch.empty([128, 128], dtype=torch.float32))
        self.register_buffer("c82", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c83", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c84", torch.empty([13, 128], dtype=torch.float32))
        self.register_buffer("c85", torch.empty([128, 128], dtype=torch.float32))
        self.register_buffer("c86", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c87", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c88", torch.empty([6, 128], dtype=torch.float32))
        self.register_buffer("c89", torch.empty([128, 128], dtype=torch.float32))
        self.register_buffer("c90", torch.empty([1], dtype=torch.int64))
        self.register_buffer("c91", torch.empty([1], dtype=torch.int64))
        self.relu1 = nn.ReLU()
        self.relu2 = nn.ReLU()
        self.relu3 = nn.ReLU()
        self.relu4 = nn.ReLU()
        self.relu5 = nn.ReLU()
        self.relu6 = nn.ReLU()
        self.linear1 = nn.Linear(384, 128)
        self.relu7 = nn.ReLU()
        self.linear2 = nn.Linear(128, 1)
        self.sigmoid1 = nn.Sigmoid()
        self.relu8 = nn.ReLU()
        self.relu9 = nn.ReLU()
        self.relu10 = nn.ReLU()
        self.relu11 = nn.ReLU()
        self.relu12 = nn.ReLU()
        self.relu13 = nn.ReLU()
        self.linear3 = nn.Linear(384, 128)
        self.relu14 = nn.ReLU()
        self.linear4 = nn.Linear(128, 1)
        self.sigmoid2 = nn.Sigmoid()

    def forward(self, x0):
        x1 = x0[:, 0:11]
        x2 = x0[:, 11:]
        x3 = x1[:, 0:3]
        x4 = x3[:, :, 0:7]
        x5, x6 = x4.split([6, 1], dim=-1)
        x7 = x1[:, 3:9]
        x8 = x7[:, :, 0:14]
        x9, x10 = x8.split([13, 1], dim=-1)
        x11 = x1[:, 9:11]
        x12 = x11[:, :, 0:7]
        x13, x14 = x12.split([6, 1], dim=-1)
        x15 = x5 @ self.c35
        x16 = self.c36 + x15
        x17 = self.relu1(x16)
        x18 = x17 @ self.c37
        x19 = self.c38 + x18
        x20 = self.relu2(x19)
        x21 = x20 * x6
        x22 = torch.sum(x21, self.c39.tolist(), keepdim=False)
        x23 = torch.sum(x6, self.c40.tolist(), keepdim=False)
        x24 = x22 / x23
        x25 = x9 @ self.c41
        x26 = self.c42 + x25
        x27 = self.relu3(x26)
        x28 = x27 @ self.c43
        x29 = self.c44 + x28
        x30 = self.relu4(x29)
        x31 = x30 * x10
        x32 = torch.sum(x31, self.c45.tolist(), keepdim=False)
        x33 = torch.sum(x10, self.c46.tolist(), keepdim=False)
        x34 = x32 / x33
        x35 = x13 @ self.c47
        x36 = self.c48 + x35
        x37 = self.relu5(x36)
        x38 = x37 @ self.c49
        x39 = self.c50 + x38
        x40 = self.relu6(x39)
        x41 = x40 * x14
        x42 = torch.sum(x41, self.c51.tolist(), keepdim=False)
        x43 = torch.sum(x14, self.c52.tolist(), keepdim=False)
        x44 = x42 / x43
        x45 = torch.cat([x24, x34, x44], dim=1)
        x46 = self.linear1(x45)
        x47 = self.relu7(x46)
        x48 = self.linear2(x47)
        x49 = self.sigmoid1(x48)
        x50 = x2[:, 0:3]
        x51 = x50[:, :, 0:7]
        x52, x53 = x51.split([6, 1], dim=-1)
        x54 = x2[:, 3:9]
        x55 = x54[:, :, 0:14]
        x56, x57 = x55.split([13, 1], dim=-1)
        x58 = x2[:, 9:11]
        x59 = x58[:, :, 0:7]
        x60, x61 = x59.split([6, 1], dim=-1)
        x62 = x52 @ self.c80
        x63 = self.c36 + x62
        x64 = self.relu8(x63)
        x65 = x64 @ self.c81
        x66 = self.c38 + x65
        x67 = self.relu9(x66)
        x68 = x67 * x53
        x69 = torch.sum(x68, self.c82.tolist(), keepdim=False)
        x70 = torch.sum(x53, self.c83.tolist(), keepdim=False)
        x71 = x69 / x70
        x72 = x56 @ self.c84
        x73 = self.c42 + x72
        x74 = self.relu10(x73)
        x75 = x74 @ self.c85
        x76 = self.c44 + x75
        x77 = self.relu11(x76)
        x78 = x77 * x57
        x79 = torch.sum(x78, self.c86.tolist(), keepdim=False)
        x80 = torch.sum(x57, self.c87.tolist(), keepdim=False)
        x81 = x79 / x80
        x82 = x60 @ self.c88
        x83 = self.c48 + x82
        x84 = self.relu12(x83)
        x85 = x84 @ self.c89
        x86 = self.c50 + x85
        x87 = self.relu13(x86)
        x88 = x87 * x61
        x89 = torch.sum(x88, self.c90.tolist(), keepdim=False)
        x90 = torch.sum(x61, self.c91.tolist(), keepdim=False)
        x91 = x89 / x90
        x92 = torch.cat([x71, x81, x91], dim=1)
        x93 = self.linear3(x92)
        x94 = self.relu14(x93)
        x95 = self.linear4(x94)
        x96 = self.sigmoid2(x95)
        x97 = x49 - x96
        return x97
