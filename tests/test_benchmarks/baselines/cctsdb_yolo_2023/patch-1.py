"""PyTorch module generated by TorchONNX.

Source: /mnt/hdd1/zhongkui/rover_project/rover_alpha/torchonnx/tests/vnncomp2024_benchmarks/cctsdb_yolo_2023/onnx/patch-1.onnx
Generated: 2025-12-22 03:36:13

This module was automatically converted from an ONNX model.
"""

__all__ = ["CctsdbYolo2023Patch1"]

import torch
import torch.nn as nn


def dynamic_slice(data, starts, ends, axes=None, steps=None, slice_lengths=None):
    """Vmap-compatible dynamic slice helper for ONNX Slice operation.

    Returns a tuple (result, valid_flag) where:
    - result: The sliced data (zeros if slice was empty/out-of-bounds)
    - valid_flag: 1.0 if slice was non-empty, 0.0 if empty

    The valid_flag should be accumulated across multiple slices and passed
    to scatter_nd to determine whether to actually perform the scatter.

    For vmap compatibility:
    - axes/steps MUST be constant (Python ints or lists)
    - starts/ends can be tensors (input-dependent)
    - slice_lengths MUST be provided (list of ints, one per axis)

    Args:
        data: Input tensor to slice
        starts: Start indices (tensor or list)
        ends: End indices (tensor or list)
        axes: Axes to slice along (constant list or None)
        steps: Step sizes (constant list or None, must be 1 for now)
        slice_lengths: Static slice lengths for each axis (REQUIRED for vmap mode)
    """
    # Convert to tensors if needed
    starts = torch.as_tensor(starts, device=data.device)
    ends = torch.as_tensor(ends, device=data.device)

    # Handle axes - MUST be constant for vmap compatibility
    if axes is None:
        axes_list = list(range(starts.numel()))
    elif isinstance(axes, (list, tuple)):
        axes_list = list(axes)
    elif isinstance(axes, torch.Tensor):
        axes_list = axes.tolist()
        if not isinstance(axes_list, list):
            axes_list = [axes_list]
    else:
        axes_list = [int(axes)]

    # Handle steps - MUST be constant for vmap compatibility
    if steps is None:
        steps_list = [1] * len(axes_list)
    elif isinstance(steps, (list, tuple)):
        steps_list = list(steps)
    elif isinstance(steps, torch.Tensor):
        steps_list = steps.tolist()
        if not isinstance(steps_list, list):
            steps_list = [steps_list]
    else:
        steps_list = [int(steps)]

    # Handle slice_lengths - default to 1 if not provided
    if slice_lengths is None:
        lengths_list = [1] * len(axes_list)
    else:
        lengths_list = list(slice_lengths)

    result = data
    # Track validity: 1.0 if all slices non-empty, 0.0 if any slice empty
    cumulative_valid = torch.ones((), dtype=data.dtype, device=data.device)

    for i, (axis, step, slice_len) in enumerate(
        zip(axes_list, steps_list, lengths_list, strict=False)
    ):
        axis = int(axis)
        step = int(step)
        slice_len = int(slice_len)
        dim_size = result.shape[axis]

        # Get start for this axis (handle scalar or 1D tensor)
        if starts.numel() == 1:
            start = starts.reshape(())
        else:
            start = starts[i]

        # Normalize negative start index
        start = torch.where(start < 0, dim_size + start, start)

        # Clamp start to valid range
        start = torch.clamp(start.long(), 0, dim_size)

        # Check if slice would be out of bounds (start + slice_len > dim_size)
        # is_valid = 1.0 if in bounds, 0.0 if out of bounds
        is_valid = (start + slice_len <= dim_size).to(data.dtype)
        cumulative_valid = cumulative_valid * is_valid

        # Generate indices for gather: start, start+step, start+2*step, ...
        # These are relative offsets that we add to start
        offsets = torch.arange(slice_len, device=data.device, dtype=torch.long) * step

        # Compute actual indices: start + offsets
        # Clamp to valid range (even if out of bounds, we need valid indices for gather)
        indices = (start + offsets).clamp(0, dim_size - 1)

        # Reshape indices for gather: [slice_len] -> proper broadcast shape
        # indices needs shape where axis dimension is slice_len, others are 1
        shape = [1] * result.ndim
        shape[axis] = slice_len
        indices = indices.view(*shape)

        # Expand indices to match result shape except for the slice axis
        expand_shape = list(result.shape)
        expand_shape[axis] = slice_len
        indices = indices.expand(*expand_shape)

        # Gather along axis
        result = torch.gather(result, axis, indices)

    # Return both the result and validity flag
    # Result is multiplied by validity so out-of-bounds slices return zeros
    return result * cumulative_valid, cumulative_valid


def scatter_nd(data, indices, updates, reduction="none", valid=None):
    """Vmap-compatible PyTorch equivalent of ONNX ScatterND.

    Uses functional torch.scatter instead of in-place index_put_ to be
    compatible with vmap and functorch transforms.

    Args:
        data: Target tensor to scatter into
        indices: (..., K) where K is the number of dimensions to index
        updates: Values to scatter
        reduction: "none" or "add"
        valid: Optional validity flag (scalar tensor). If provided and < 0.5,
               returns data unchanged (simulates empty scatter from empty slices).

    When valid=0 (from out-of-bounds slices), returns original data unchanged,
    matching the behavior of standard mode where empty slices cause no scatter.
    """
    indices = indices.to(torch.long)
    updates = updates.to(data.dtype)

    # Compute linear indices from N-D indices
    # strides[i] = product of data.shape[i+1:]
    data_shape = torch.tensor(data.shape, device=data.device, dtype=torch.long)
    k = indices.shape[-1]

    # Compute strides for the first K dimensions
    strides = torch.ones(k, device=data.device, dtype=torch.long)
    for i in range(k - 2, -1, -1):
        strides[i] = strides[i + 1] * data_shape[i + 1]

    # Compute linear indices
    linear_idx = (indices * strides).sum(dim=-1)

    # Flatten data and updates
    flat_data = data.reshape(-1)
    flat_updates = updates.reshape(-1)
    linear_idx = linear_idx.reshape(-1)

    # Use functional scatter
    if reduction == "none":
        scattered = flat_data.scatter(0, linear_idx, flat_updates)
    elif reduction == "add":
        scattered = flat_data.scatter_add(0, linear_idx, flat_updates)
    else:
        raise NotImplementedError(f"Unsupported reduction: {reduction}")

    result = scattered.reshape(data.shape)

    # If valid flag provided, use it to select between scattered result and original data
    # valid > 0.5 means slices were non-empty, so use scattered result
    # valid <= 0.5 means slices were empty, so return original data unchanged
    if valid is not None:
        # Use torch.where for vmap compatibility (no Python if/else branching)
        result = torch.where(valid > 0.5, result, data)

    return result


def dynamic_expand(data, target_shape):
    """Vmap-compatible dynamic expand helper for ONNX Expand operation.

    This version handles the conversion from ONNX semantics to PyTorch
    while remaining compatible with vmap.

    Note: For full vmap compatibility, target_shape should be constant
    (known at code generation time). Dynamic target_shape from tensors
    may still work but with limitations.
    """
    # Convert target_shape to list of ints
    if isinstance(target_shape, torch.Tensor):
        target_shape = target_shape.to(torch.int64).tolist()
    target_shape = [int(x) for x in target_shape]

    # If data has more dimensions than target, squeeze leading dimensions
    if data.ndim > len(target_shape):
        new_shape = tuple(int(s) for s in data.shape[data.ndim - len(target_shape) :])
        data = data.reshape(new_shape)

    # Convert ONNX semantics to PyTorch
    # ONNX: 1 means "keep dimension", PyTorch: -1 means "keep dimension"
    converted_shape = []
    offset = len(target_shape) - data.ndim

    for i in range(len(target_shape)):
        if i < offset:
            # Dimension doesn't exist in data, use target value
            converted_shape.append(target_shape[i])
        else:
            # Dimension exists in data
            data_idx = i - offset
            if target_shape[i] == 1 and data.shape[data_idx] != 1:
                # Keep data's dimension
                converted_shape.append(-1)
            else:
                # Use target dimension
                converted_shape.append(target_shape[i])

    return data.expand(*converted_shape)


class CctsdbYolo2023Patch1(nn.Module):
    def __init__(self):
        super().__init__()
        self.register_buffer("c26", torch.empty([1, 1, 1, 64], dtype=torch.float32))
        self.conv2d1 = nn.Conv2d(3, 24, 3, stride=2, padding=1)
        self.relu1 = nn.ReLU()
        self.maxpool2d1 = nn.MaxPool2d((3, 3), stride=2, padding=1)
        self.conv2d2 = nn.Conv2d(24, 24, 3, stride=2, padding=1, groups=24)
        self.conv2d3 = nn.Conv2d(24, 24, 1)
        self.relu2 = nn.ReLU()
        self.conv2d4 = nn.Conv2d(24, 24, 1)
        self.relu3 = nn.ReLU()
        self.conv2d5 = nn.Conv2d(24, 24, 3, stride=2, padding=1, groups=24)
        self.conv2d6 = nn.Conv2d(24, 24, 1)
        self.relu4 = nn.ReLU()
        self.conv2d7 = nn.Conv2d(48, 48, 3, stride=2, padding=1, groups=48)
        self.conv2d8 = nn.Conv2d(48, 48, 1)
        self.relu5 = nn.ReLU()
        self.conv2d9 = nn.Conv2d(48, 48, 1)
        self.relu6 = nn.ReLU()
        self.conv2d10 = nn.Conv2d(48, 48, 3, stride=2, padding=1, groups=48)
        self.conv2d11 = nn.Conv2d(48, 48, 1)
        self.relu7 = nn.ReLU()
        self.conv2d12 = nn.Conv2d(48, 48, 1)
        self.relu8 = nn.ReLU()
        self.conv2d13 = nn.Conv2d(48, 48, 3, padding=1, groups=48)
        self.conv2d14 = nn.Conv2d(48, 48, 1)
        self.relu9 = nn.ReLU()
        self.conv2d15 = nn.Conv2d(96, 96, 3, stride=2, padding=1, groups=96)
        self.conv2d16 = nn.Conv2d(96, 96, 1)
        self.relu10 = nn.ReLU()
        self.conv2d17 = nn.Conv2d(96, 96, 1)
        self.relu11 = nn.ReLU()
        self.conv2d18 = nn.Conv2d(96, 96, 3, stride=2, padding=1, groups=96)
        self.conv2d19 = nn.Conv2d(96, 96, 1)
        self.relu12 = nn.ReLU()
        self.upsample1 = nn.Upsample(scale_factor=(2.0, 2.0))
        self.conv2d20 = nn.Conv2d(288, 72, 1)
        self.relu13 = nn.ReLU()
        self.conv2d21 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu14 = nn.ReLU()
        self.conv2d22 = nn.Conv2d(72, 72, 1)
        self.conv2d23 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu15 = nn.ReLU()
        self.conv2d24 = nn.Conv2d(72, 72, 1)
        self.conv2d25 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu16 = nn.ReLU()
        self.conv2d26 = nn.Conv2d(72, 72, 1)
        self.conv2d27 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu17 = nn.ReLU()
        self.conv2d28 = nn.Conv2d(72, 72, 1)
        self.conv2d29 = nn.Conv2d(72, 4, 3, stride=2)
        self.conv2d30 = nn.Conv2d(72, 3, 3, stride=2)

    def forward(self, x0):
        _slice_valid = torch.ones((), dtype=x0.dtype, device=x0.device)
        x1 = x0[0:12288]
        x2 = x1.reshape(-1, 3, 64, 64)
        x3 = x0[12288]
        x4 = x3.to(torch.int64)
        x5 = x0[12289]
        x6 = x5.to(torch.int64)
        x7 = x0[12290:]
        x8 = x7[2:6]
        x9 = x7[1]
        x10 = torch.tensor(x2.shape, dtype=torch.int64, device=x2.device)
        x11 = torch.full(x10.tolist(), 1.0, dtype=torch.float32, device=x0.device)
        x12 = x4 + 1
        x13 = x6 + 1
        x14 = x4.unsqueeze(0)
        x15 = x12.unsqueeze(0)
        x16, x16_valid = dynamic_slice(x11, x14, x15, [1], [1], [1])
        _slice_valid = _slice_valid * x16_valid
        x17 = x6.unsqueeze(0)
        x18 = x13.unsqueeze(0)
        x19, x19_valid = dynamic_slice(x16, x17, x18, [2], [1], [1])
        _slice_valid = _slice_valid * x19_valid
        x20 = torch.tensor(x19.shape, dtype=torch.int64, device=x19.device)
        x21 = dynamic_expand(self.c26, x20)
        x22 = torch.tensor(x11.shape, dtype=torch.int64, device=x11.device)
        x23 = x22[0]
        x24 = x23.to(torch.int64)
        x25 = torch.arange(0, x24, 1, device=x24.device)
        x26 = torch.tensor(x11.shape, dtype=torch.int64, device=x11.device)
        x27 = x26[1]
        x28 = x27.to(torch.int64)
        x29 = torch.arange(0, x28, 1, device=x28.device)
        x30 = x4.unsqueeze(0)
        x31 = x12.unsqueeze(0)
        x32, x32_valid = dynamic_slice(x29, x30, x31, [0], [1], [1])
        _slice_valid = _slice_valid * x32_valid
        x33 = torch.tensor(x11.shape, dtype=torch.int64, device=x11.device)
        x34 = x33[2]
        x35 = x34.to(torch.int64)
        x36 = torch.arange(0, x35, 1, device=x35.device)
        x37 = x6.unsqueeze(0)
        x38 = x13.unsqueeze(0)
        x39, x39_valid = dynamic_slice(x36, x37, x38, [0], [1], [1])
        _slice_valid = _slice_valid * x39_valid
        x40 = torch.tensor(x11.shape, dtype=torch.int64, device=x11.device)
        x41 = x40[3]
        x42 = x41.to(torch.int64)
        x43 = torch.arange(0, x42, 1, device=x42.device)
        x44 = x25.reshape(-1, 1, 1, 1)
        x45 = x32.reshape(-1, 1, 1)
        x46 = x39.reshape(-1, 1)
        x47 = x44 + x45
        x48 = x47 + x46
        x49 = x48 + x43
        x50 = torch.tensor(x49.shape, dtype=torch.int64, device=x49.device)
        x51 = torch.tensor(x50.shape, dtype=torch.int64, device=x50.device)
        x52 = torch.full(x51.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x53 = x52 * -1
        x54 = x50 == x53
        x55 = torch.where(x54, x52, x50)
        x56 = dynamic_expand(x44, x55)
        x57 = x56.unsqueeze(-1)
        x58 = torch.tensor(x50.shape, dtype=torch.int64, device=x50.device)
        x59 = torch.full(x58.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x60 = x59 * -1
        x61 = x50 == x60
        x62 = torch.where(x61, x59, x50)
        x63 = dynamic_expand(x45, x62)
        x64 = x63.unsqueeze(-1)
        x65 = torch.tensor(x50.shape, dtype=torch.int64, device=x50.device)
        x66 = torch.full(x65.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x67 = x66 * -1
        x68 = x50 == x67
        x69 = torch.where(x68, x66, x50)
        x70 = dynamic_expand(x46, x69)
        x71 = x70.unsqueeze(-1)
        x72 = torch.tensor(x50.shape, dtype=torch.int64, device=x50.device)
        x73 = torch.full(x72.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x74 = x73 * -1
        x75 = x50 == x74
        x76 = torch.where(x75, x73, x50)
        x77 = dynamic_expand(x43, x76)
        x78 = x77.unsqueeze(-1)
        x79 = torch.cat([x57, x64, x71, x78], dim=-1)
        x80 = torch.tensor(x11.shape, dtype=torch.int64, device=x11.device)
        x81 = x80[4:]
        x82 = torch.cat([x50, x81])
        x83 = x21.reshape([int(x) for x in x82.tolist()])
        x84 = scatter_nd(x11, x79, x83, valid=_slice_valid)
        x85 = x2 * x84
        x86 = self.conv2d1(x85)
        x87 = self.relu1(x86)
        x88 = self.maxpool2d1(x87)
        x89 = self.conv2d2(x88)
        x90 = self.conv2d3(x89)
        x91 = self.relu2(x90)
        x92 = self.conv2d4(x88)
        x93 = self.relu3(x92)
        x94 = self.conv2d5(x93)
        x95 = self.conv2d6(x94)
        x96 = self.relu4(x95)
        x97 = torch.cat([x91, x96], dim=1)
        x98 = self.conv2d7(x97)
        x99 = self.conv2d8(x98)
        x100 = self.relu5(x99)
        x101 = self.conv2d9(x97)
        x102 = self.relu6(x101)
        x103 = self.conv2d10(x102)
        x104 = self.conv2d11(x103)
        x105 = self.relu7(x104)
        x106 = torch.cat([x100, x105], dim=1)
        x107 = x106.reshape(48, 2, 16)
        x108 = x107.permute((1, 0, 2))
        x109 = x108.reshape(2, -1, 48, 4, 4)
        x110 = x109[0]
        x111 = x109[1]
        x112 = self.conv2d12(x111)
        x113 = self.relu8(x112)
        x114 = self.conv2d13(x113)
        x115 = self.conv2d14(x114)
        x116 = self.relu9(x115)
        x117 = torch.cat([x110, x116], dim=1)
        x118 = self.conv2d15(x117)
        x119 = self.conv2d16(x118)
        x120 = self.relu10(x119)
        x121 = self.conv2d17(x117)
        x122 = self.relu11(x121)
        x123 = self.conv2d18(x122)
        x124 = self.conv2d19(x123)
        x125 = self.relu12(x124)
        x126 = torch.cat([x120, x125], dim=1)
        x127 = self.upsample1(x126)
        x128 = torch.cat([x127, x117], dim=1)
        x129 = self.conv2d20(x128)
        x130 = self.relu13(x129)
        x131 = self.conv2d21(x130)
        x132 = self.relu14(x131)
        x133 = self.conv2d22(x132)
        x134 = self.conv2d23(x133)
        x135 = self.relu15(x134)
        x136 = self.conv2d24(x135)
        x137 = self.conv2d25(x130)
        x138 = self.relu16(x137)
        x139 = self.conv2d26(x138)
        x140 = self.conv2d27(x139)
        x141 = self.relu17(x140)
        x142 = self.conv2d28(x141)
        x143 = self.conv2d29(x142)
        x144 = self.conv2d30(x136)
        x145 = x143.squeeze(3)
        x146 = x145.squeeze(2)
        x147 = x144.squeeze(3)
        x148 = x147.squeeze(2)
        x149 = torch.argmax(x148, dim=1, keepdim=False)
        x150 = x149.to(torch.float32)
        x151 = x150 == x9
        x152 = x151.to(torch.bool)
        x153 = x8[0]
        x154 = x8[1]
        x155 = x8[2]
        x156 = x8[3]
        x157 = x146[0]
        x158 = x157[0]
        x159 = x146[0]
        x160 = x159[1]
        x161 = x146[0]
        x162 = x161[2]
        x163 = x146[0]
        x164 = x163[3]
        x165 = torch.min(x155, x162)
        x166 = torch.max(x153, x158)
        x167 = x165 - x166
        x168 = torch.clamp(x167, min=0)
        x169 = torch.min(x156, x164)
        x170 = torch.max(x154, x160)
        x171 = x169 - x170
        x172 = torch.clamp(x171, min=0)
        x173 = x168 * x172
        x174 = x155 - x153
        x175 = x156 - x154
        x176 = x162 - x158
        x177 = x164 - x160
        x178 = x174 * x175
        x179 = x178 + 1.0000000168623835e-16
        x180 = x176 * x177
        x181 = x179 + x180
        x182 = x181 - x173
        x183 = x173 / x182
        x184 = x183.to(torch.float32)
        x185 = x152.to(torch.int64)
        x186 = x185.to(torch.float32)
        x187 = x186 * x184
        return x187
