"""PyTorch module generated by TorchONNX.

Source: /mnt/hdd1/zhongkui/rover_project/rover_alpha/torchonnx/tests/vnncomp2024_benchmarks/cctsdb_yolo_2023/onnx/patch-3.onnx
Generated: 2025-12-22 03:36:13

This module was automatically converted from an ONNX model.
"""

__all__ = ["CctsdbYolo2023Patch3"]

import torch
import torch.nn as nn


def dynamic_slice(data, starts, ends, axes=None, steps=None, slice_lengths=None):
    """Vmap-compatible dynamic slice helper for ONNX Slice operation.

    Returns a tuple (result, valid_flag) where:
    - result: The sliced data (zeros if slice was empty/out-of-bounds)
    - valid_flag: 1.0 if slice was non-empty, 0.0 if empty

    The valid_flag should be accumulated across multiple slices and passed
    to scatter_nd to determine whether to actually perform the scatter.

    For vmap compatibility:
    - axes/steps MUST be constant (Python ints or lists)
    - starts/ends can be tensors (input-dependent)
    - slice_lengths MUST be provided (list of ints, one per axis)

    Args:
        data: Input tensor to slice
        starts: Start indices (tensor or list)
        ends: End indices (tensor or list)
        axes: Axes to slice along (constant list or None)
        steps: Step sizes (constant list or None, must be 1 for now)
        slice_lengths: Static slice lengths for each axis (REQUIRED for vmap mode)
    """
    # Convert to tensors if needed
    starts = torch.as_tensor(starts, device=data.device)
    ends = torch.as_tensor(ends, device=data.device)

    # Handle axes - MUST be constant for vmap compatibility
    if axes is None:
        axes_list = list(range(starts.numel()))
    elif isinstance(axes, (list, tuple)):
        axes_list = list(axes)
    elif isinstance(axes, torch.Tensor):
        axes_list = axes.tolist()
        if not isinstance(axes_list, list):
            axes_list = [axes_list]
    else:
        axes_list = [int(axes)]

    # Handle steps - MUST be constant for vmap compatibility
    if steps is None:
        steps_list = [1] * len(axes_list)
    elif isinstance(steps, (list, tuple)):
        steps_list = list(steps)
    elif isinstance(steps, torch.Tensor):
        steps_list = steps.tolist()
        if not isinstance(steps_list, list):
            steps_list = [steps_list]
    else:
        steps_list = [int(steps)]

    # Handle slice_lengths - default to 1 if not provided
    if slice_lengths is None:
        lengths_list = [1] * len(axes_list)
    else:
        lengths_list = list(slice_lengths)

    result = data
    # Track validity: 1.0 if all slices non-empty, 0.0 if any slice empty
    cumulative_valid = torch.ones((), dtype=data.dtype, device=data.device)

    for i, (axis, step, slice_len) in enumerate(
        zip(axes_list, steps_list, lengths_list, strict=False)
    ):
        axis = int(axis)
        step = int(step)
        slice_len = int(slice_len)
        dim_size = result.shape[axis]

        # Get start for this axis (handle scalar or 1D tensor)
        if starts.numel() == 1:
            start = starts.reshape(())
        else:
            start = starts[i]

        # Normalize negative start index
        start = torch.where(start < 0, dim_size + start, start)

        # Clamp start to valid range
        start = torch.clamp(start.long(), 0, dim_size)

        # Check if slice would be out of bounds (start + slice_len > dim_size)
        # is_valid = 1.0 if in bounds, 0.0 if out of bounds
        is_valid = (start + slice_len <= dim_size).to(data.dtype)
        cumulative_valid = cumulative_valid * is_valid

        # Generate indices for gather: start, start+step, start+2*step, ...
        # These are relative offsets that we add to start
        offsets = torch.arange(slice_len, device=data.device, dtype=torch.long) * step

        # Compute actual indices: start + offsets
        # Clamp to valid range (even if out of bounds, we need valid indices for gather)
        indices = (start + offsets).clamp(0, dim_size - 1)

        # Reshape indices for gather: [slice_len] -> proper broadcast shape
        # indices needs shape where axis dimension is slice_len, others are 1
        shape = [1] * result.ndim
        shape[axis] = slice_len
        indices = indices.view(*shape)

        # Expand indices to match result shape except for the slice axis
        expand_shape = list(result.shape)
        expand_shape[axis] = slice_len
        indices = indices.expand(*expand_shape)

        # Gather along axis
        result = torch.gather(result, axis, indices)

    # Return both the result and validity flag
    # Result is multiplied by validity so out-of-bounds slices return zeros
    return result * cumulative_valid, cumulative_valid


def scatter_nd(data, indices, updates, reduction="none", valid=None):
    """Vmap-compatible PyTorch equivalent of ONNX ScatterND.

    Uses functional torch.scatter instead of in-place index_put_ to be
    compatible with vmap and functorch transforms.

    Args:
        data: Target tensor to scatter into
        indices: (..., K) where K is the number of dimensions to index
        updates: Values to scatter
        reduction: "none" or "add"
        valid: Optional validity flag (scalar tensor). If provided and < 0.5,
               returns data unchanged (simulates empty scatter from empty slices).

    When valid=0 (from out-of-bounds slices), returns original data unchanged,
    matching the behavior of standard mode where empty slices cause no scatter.
    """
    indices = indices.to(torch.long)
    updates = updates.to(data.dtype)

    # Compute linear indices from N-D indices
    # strides[i] = product of data.shape[i+1:]
    data_shape = torch.tensor(data.shape, device=data.device, dtype=torch.long)
    k = indices.shape[-1]

    # Compute strides for the first K dimensions
    strides = torch.ones(k, device=data.device, dtype=torch.long)
    for i in range(k - 2, -1, -1):
        strides[i] = strides[i + 1] * data_shape[i + 1]

    # Compute linear indices
    linear_idx = (indices * strides).sum(dim=-1)

    # Flatten data and updates
    flat_data = data.reshape(-1)
    flat_updates = updates.reshape(-1)
    linear_idx = linear_idx.reshape(-1)

    # Use functional scatter
    if reduction == "none":
        scattered = flat_data.scatter(0, linear_idx, flat_updates)
    elif reduction == "add":
        scattered = flat_data.scatter_add(0, linear_idx, flat_updates)
    else:
        raise NotImplementedError(f"Unsupported reduction: {reduction}")

    result = scattered.reshape(data.shape)

    # If valid flag provided, use it to select between scattered result and original data
    # valid > 0.5 means slices were non-empty, so use scattered result
    # valid <= 0.5 means slices were empty, so return original data unchanged
    if valid is not None:
        # Use torch.where for vmap compatibility (no Python if/else branching)
        result = torch.where(valid > 0.5, result, data)

    return result


def dynamic_expand(data, target_shape):
    """Vmap-compatible dynamic expand helper for ONNX Expand operation.

    This version handles the conversion from ONNX semantics to PyTorch
    while remaining compatible with vmap.

    Note: For full vmap compatibility, target_shape should be constant
    (known at code generation time). Dynamic target_shape from tensors
    may still work but with limitations.
    """
    # Convert target_shape to list of ints
    if isinstance(target_shape, torch.Tensor):
        target_shape = target_shape.to(torch.int64).tolist()
    target_shape = [int(x) for x in target_shape]

    # If data has more dimensions than target, squeeze leading dimensions
    if data.ndim > len(target_shape):
        new_shape = tuple(int(s) for s in data.shape[data.ndim - len(target_shape) :])
        data = data.reshape(new_shape)

    # Convert ONNX semantics to PyTorch
    # ONNX: 1 means "keep dimension", PyTorch: -1 means "keep dimension"
    converted_shape = []
    offset = len(target_shape) - data.ndim

    for i in range(len(target_shape)):
        if i < offset:
            # Dimension doesn't exist in data, use target value
            converted_shape.append(target_shape[i])
        else:
            # Dimension exists in data
            data_idx = i - offset
            if target_shape[i] == 1 and data.shape[data_idx] != 1:
                # Keep data's dimension
                converted_shape.append(-1)
            else:
                # Use target dimension
                converted_shape.append(target_shape[i])

    return data.expand(*converted_shape)


class CctsdbYolo2023Patch3(nn.Module):
    def __init__(self):
        super().__init__()
        self.register_buffer("c20", torch.empty([1, 3, 64, 64], dtype=torch.float32))
        self.register_buffer("c29", torch.empty([3], dtype=torch.int64))
        self.register_buffer("c34", torch.empty([64], dtype=torch.int64))
        self.register_buffer("c40", torch.empty([64], dtype=torch.int64))
        self.register_buffer("c42", torch.empty([1, 1, 1, 1], dtype=torch.int64))
        self.register_buffer("c49", torch.empty([64], dtype=torch.int64))
        self.register_buffer("c51", torch.empty([0], dtype=torch.int64))
        self.conv2d1 = nn.Conv2d(3, 24, 3, stride=2, padding=1)
        self.relu1 = nn.ReLU()
        self.maxpool2d1 = nn.MaxPool2d((3, 3), stride=2, padding=1)
        self.conv2d2 = nn.Conv2d(24, 24, 3, stride=2, padding=1, groups=24)
        self.conv2d3 = nn.Conv2d(24, 24, 1)
        self.relu2 = nn.ReLU()
        self.conv2d4 = nn.Conv2d(24, 24, 1)
        self.relu3 = nn.ReLU()
        self.conv2d5 = nn.Conv2d(24, 24, 3, stride=2, padding=1, groups=24)
        self.conv2d6 = nn.Conv2d(24, 24, 1)
        self.relu4 = nn.ReLU()
        self.conv2d7 = nn.Conv2d(48, 48, 3, stride=2, padding=1, groups=48)
        self.conv2d8 = nn.Conv2d(48, 48, 1)
        self.relu5 = nn.ReLU()
        self.conv2d9 = nn.Conv2d(48, 48, 1)
        self.relu6 = nn.ReLU()
        self.conv2d10 = nn.Conv2d(48, 48, 3, stride=2, padding=1, groups=48)
        self.conv2d11 = nn.Conv2d(48, 48, 1)
        self.relu7 = nn.ReLU()
        self.conv2d12 = nn.Conv2d(48, 48, 1)
        self.relu8 = nn.ReLU()
        self.conv2d13 = nn.Conv2d(48, 48, 3, padding=1, groups=48)
        self.conv2d14 = nn.Conv2d(48, 48, 1)
        self.relu9 = nn.ReLU()
        self.conv2d15 = nn.Conv2d(96, 96, 3, stride=2, padding=1, groups=96)
        self.conv2d16 = nn.Conv2d(96, 96, 1)
        self.relu10 = nn.ReLU()
        self.conv2d17 = nn.Conv2d(96, 96, 1)
        self.relu11 = nn.ReLU()
        self.conv2d18 = nn.Conv2d(96, 96, 3, stride=2, padding=1, groups=96)
        self.conv2d19 = nn.Conv2d(96, 96, 1)
        self.relu12 = nn.ReLU()
        self.upsample1 = nn.Upsample(scale_factor=(2.0, 2.0))
        self.conv2d20 = nn.Conv2d(288, 72, 1)
        self.relu13 = nn.ReLU()
        self.conv2d21 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu14 = nn.ReLU()
        self.conv2d22 = nn.Conv2d(72, 72, 1)
        self.conv2d23 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu15 = nn.ReLU()
        self.conv2d24 = nn.Conv2d(72, 72, 1)
        self.conv2d25 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu16 = nn.ReLU()
        self.conv2d26 = nn.Conv2d(72, 72, 1)
        self.conv2d27 = nn.Conv2d(72, 72, 5, padding=2, groups=72)
        self.relu17 = nn.ReLU()
        self.conv2d28 = nn.Conv2d(72, 72, 1)
        self.conv2d29 = nn.Conv2d(72, 4, 3, stride=2)
        self.conv2d30 = nn.Conv2d(72, 3, 3, stride=2)

    def forward(self, x0):
        _slice_valid = torch.ones((), dtype=x0.dtype, device=x0.device)
        x1 = x0[0:12288]
        x2 = x1.reshape(-1, 3, 64, 64)
        x3 = x0[12288]
        x4 = x3.to(torch.int64)
        x5 = x0[12289]
        x6 = x5.to(torch.int64)
        x7 = x0[12290:]
        x8 = x7[2:6]
        x9 = x7[1]
        x10 = x4 + 3
        x11 = x6 + 3
        x12 = x4.unsqueeze(0)
        x13 = x10.unsqueeze(0)
        x14, x14_valid = dynamic_slice(self.c20, x12, x13, [1], [1], [3])
        _slice_valid = _slice_valid * x14_valid
        x15 = x6.unsqueeze(0)
        x16 = x11.unsqueeze(0)
        x17, x17_valid = dynamic_slice(x14, x15, x16, [2], [1], [3])
        _slice_valid = _slice_valid * x17_valid
        x18 = torch.tensor(x17.shape, dtype=torch.int64, device=x17.device)
        x19 = torch.full(x18.tolist(), 0.0, dtype=torch.float32, device=x0.device)
        x20 = torch.tensor(x17.shape, dtype=torch.int64, device=x17.device)
        x21 = dynamic_expand(x19, x20)
        x22 = x4.unsqueeze(0)
        x23 = x10.unsqueeze(0)
        x24, x24_valid = dynamic_slice(self.c29, x22, x23, [0], [1], [3])
        _slice_valid = _slice_valid * x24_valid
        x25 = x6.unsqueeze(0)
        x26 = x11.unsqueeze(0)
        x27, x27_valid = dynamic_slice(self.c34, x25, x26, [0], [1], [3])
        _slice_valid = _slice_valid * x27_valid
        x28 = x24.reshape(-1, 1, 1)
        x29 = x27.reshape(-1, 1)
        x30 = 0 + x28
        x31 = x30 + x29
        x32 = x31 + self.c40
        x33 = torch.tensor(x32.shape, dtype=torch.int64, device=x32.device)
        x34 = torch.tensor(x33.shape, dtype=torch.int64, device=x33.device)
        x35 = torch.full(x34.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x36 = x35 * -1
        x37 = x33 == x36
        x38 = torch.where(x37, x35, x33)
        x39 = dynamic_expand(self.c42, x38)
        x40 = x39.unsqueeze(-1)
        x41 = torch.tensor(x33.shape, dtype=torch.int64, device=x33.device)
        x42 = torch.full(x41.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x43 = x42 * -1
        x44 = x33 == x43
        x45 = torch.where(x44, x42, x33)
        x46 = dynamic_expand(x28, x45)
        x47 = x46.unsqueeze(-1)
        x48 = torch.tensor(x33.shape, dtype=torch.int64, device=x33.device)
        x49 = torch.full(x48.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x50 = x49 * -1
        x51 = x33 == x50
        x52 = torch.where(x51, x49, x33)
        x53 = dynamic_expand(x29, x52)
        x54 = x53.unsqueeze(-1)
        x55 = torch.tensor(x33.shape, dtype=torch.int64, device=x33.device)
        x56 = torch.full(x55.tolist(), 1.0, dtype=torch.int64, device=x0.device)
        x57 = x56 * -1
        x58 = x33 == x57
        x59 = torch.where(x58, x56, x33)
        x60 = dynamic_expand(self.c49, x59)
        x61 = x60.unsqueeze(-1)
        x62 = torch.cat([x40, x47, x54, x61], dim=-1)
        x63 = torch.cat([x33, self.c51])
        x64 = x21.reshape([int(x) for x in x63.tolist()])
        x65 = scatter_nd(self.c20, x62, x64, valid=_slice_valid)
        x66 = x2 * x65
        x67 = self.conv2d1(x66)
        x68 = self.relu1(x67)
        x69 = self.maxpool2d1(x68)
        x70 = self.conv2d2(x69)
        x71 = self.conv2d3(x70)
        x72 = self.relu2(x71)
        x73 = self.conv2d4(x69)
        x74 = self.relu3(x73)
        x75 = self.conv2d5(x74)
        x76 = self.conv2d6(x75)
        x77 = self.relu4(x76)
        x78 = torch.cat([x72, x77], dim=1)
        x79 = self.conv2d7(x78)
        x80 = self.conv2d8(x79)
        x81 = self.relu5(x80)
        x82 = self.conv2d9(x78)
        x83 = self.relu6(x82)
        x84 = self.conv2d10(x83)
        x85 = self.conv2d11(x84)
        x86 = self.relu7(x85)
        x87 = torch.cat([x81, x86], dim=1)
        x88 = x87.reshape(48, 2, 16)
        x89 = x88.permute((1, 0, 2))
        x90 = x89.reshape(2, -1, 48, 4, 4)
        x91 = x90[0]
        x92 = x90[1]
        x93 = self.conv2d12(x92)
        x94 = self.relu8(x93)
        x95 = self.conv2d13(x94)
        x96 = self.conv2d14(x95)
        x97 = self.relu9(x96)
        x98 = torch.cat([x91, x97], dim=1)
        x99 = self.conv2d15(x98)
        x100 = self.conv2d16(x99)
        x101 = self.relu10(x100)
        x102 = self.conv2d17(x98)
        x103 = self.relu11(x102)
        x104 = self.conv2d18(x103)
        x105 = self.conv2d19(x104)
        x106 = self.relu12(x105)
        x107 = torch.cat([x101, x106], dim=1)
        x108 = self.upsample1(x107)
        x109 = torch.cat([x108, x98], dim=1)
        x110 = self.conv2d20(x109)
        x111 = self.relu13(x110)
        x112 = self.conv2d21(x111)
        x113 = self.relu14(x112)
        x114 = self.conv2d22(x113)
        x115 = self.conv2d23(x114)
        x116 = self.relu15(x115)
        x117 = self.conv2d24(x116)
        x118 = self.conv2d25(x111)
        x119 = self.relu16(x118)
        x120 = self.conv2d26(x119)
        x121 = self.conv2d27(x120)
        x122 = self.relu17(x121)
        x123 = self.conv2d28(x122)
        x124 = self.conv2d29(x123)
        x125 = self.conv2d30(x117)
        x126 = x124.squeeze(3)
        x127 = x126.squeeze(2)
        x128 = x125.squeeze(3)
        x129 = x128.squeeze(2)
        x130 = torch.argmax(x129, dim=1, keepdim=False)
        x131 = x130.to(torch.float32)
        x132 = x131 == x9
        x133 = x132.to(torch.bool)
        x134 = x8[0]
        x135 = x8[1]
        x136 = x8[2]
        x137 = x8[3]
        x138 = x127[0]
        x139 = x138[0]
        x140 = x127[0]
        x141 = x140[1]
        x142 = x127[0]
        x143 = x142[2]
        x144 = x127[0]
        x145 = x144[3]
        x146 = torch.min(x136, x143)
        x147 = torch.max(x134, x139)
        x148 = x146 - x147
        x149 = torch.clamp(x148, min=0)
        x150 = torch.min(x137, x145)
        x151 = torch.max(x135, x141)
        x152 = x150 - x151
        x153 = torch.clamp(x152, min=0)
        x154 = x149 * x153
        x155 = x136 - x134
        x156 = x137 - x135
        x157 = x143 - x139
        x158 = x145 - x141
        x159 = x155 * x156
        x160 = x159 + 1.0000000168623835e-16
        x161 = x157 * x158
        x162 = x160 + x161
        x163 = x162 - x154
        x164 = x154 / x163
        x165 = x164.to(torch.float32)
        x166 = x133.to(torch.int64)
        x167 = x166.to(torch.float32)
        x168 = x167 * x165
        return x168
